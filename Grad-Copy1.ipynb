{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX = 100\n",
    "n = 100\n",
    "\n",
    "def random(n, M = MAX):\n",
    "    return 2 * (np.random.random(n) - 0.5) * M\n",
    "\n",
    "A = torch.zeros([n, n])\n",
    "for i in range(0, n):\n",
    "    A[i] = torch.from_numpy(random(n))\n",
    "b = torch.tensor(random(n))\n",
    "\n",
    "def Ax_b(x):\n",
    "    return (torch.matmul(A, x) - b).norm()**2\n",
    "\n",
    "m = 100\n",
    "a = torch.zeros([m, n])\n",
    "for i in range(0, m):\n",
    "    a[i] = torch.from_numpy(random(n, 1))\n",
    "    \n",
    "def log_reg(x):\n",
    "    s = torch.zeros(1)\n",
    "    for i in range(0, m):\n",
    "        s += torch.log(1 + torch.exp(torch.matmul(a[i], x)))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Iterations:\n",
    "    def __init__(self, x, iters):\n",
    "        self.x = x\n",
    "        self.iters = iters\n",
    "        \n",
    "def caution(x):\n",
    "    if(x.requires_grad):\n",
    "        print('input should not require grad\\n')\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def gradient(f, x):\n",
    "    if(caution(x)):\n",
    "        return\n",
    "    x = torch.tensor(x, requires_grad = True)\n",
    "    return torch.autograd.grad(outputs = f(x), inputs = x)[0].detach()\n",
    "\n",
    "def gradient2(f, x):\n",
    "    if(caution(x)):\n",
    "        return\n",
    "    x = torch.tensor(x, requires_grad = True)\n",
    "    grad = torch.autograd.grad(outputs = f(x), inputs = x, create_graph = True)[0]\n",
    "    grad2 = torch.zeros([x.shape[0], x.shape[0]])\n",
    "    for i in range(0, x.shape[0]):\n",
    "        grad2[i] = torch.autograd.grad(outputs = grad[i], inputs = x, create_graph = True)[0]\n",
    "    return grad2.detach()\n",
    "\n",
    "def gradient3(f, x):\n",
    "    if(caution(x)):\n",
    "        return\n",
    "    x = torch.tensor(x, requires_grad = True)\n",
    "    grad = torch.autograd.grad(outputs = f(x), inputs = x, create_graph = True)[0]\n",
    "    grad2 = torch.zeros([x.shape[0], x.shape[0]])\n",
    "    for i in range(0, x.shape[0]):\n",
    "        grad2[i] = torch.autograd.grad(outputs = grad[i], inputs = x, create_graph = True)[0]\n",
    "    grad3 = torch.zeros([x.shape[0], x.shape[0], x.shape[0]])\n",
    "    for i in range(0, x.shape[0]):\n",
    "        for j in range(0, x.shape[0]):\n",
    "            grad3[i][j] = torch.autograd.grad(outputs = grad2[i][j], inputs = x, create_graph = True)[0]\n",
    "    return grad3.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NAG(f, x_0, gradient, L = 1., eps = 1e-3, max_iter = 1e4):\n",
    "    iterations = [x_0]\n",
    "    k = 0\n",
    "    y_0 = x_0\n",
    "    gradient_x0 = gradient(x_0)\n",
    "    \n",
    "    while(len(iterations) <= max_iter):\n",
    "        k += 1\n",
    "        \n",
    "        x_k = y_0 - 1./L * gradient(y_0)\n",
    "        y_k = x_k + (k - 1.)/(k + 2.) * (x_k - x_0)\n",
    "        \n",
    "        iterations.append(x_k)\n",
    "        gradient_xk = gradient(x_k)\n",
    "        \n",
    "        if(gradient_xk.norm() <= eps):\n",
    "            break\n",
    "        if(f(x_k) > f(x_0) + torch.matmul(gradient_x0, x_k - x_0) + L/2. * (x_k - x_0).norm()):\n",
    "            L *= 2\n",
    "            k -= 1\n",
    "            continue\n",
    "       \n",
    "        gradient_x0 = gradient_xk\n",
    "        x_0 = x_k\n",
    "        y_0 = y_k\n",
    "        \n",
    "    return Iterations(x_k, iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def b_r_k(x, y, f, x_k, L_3, grad_rk_x, grad2_f_xk):\n",
    "    \n",
    "    def r_k(x):\n",
    "        \n",
    "        return 0.5 * torch.matmul(torch.matmul(grad2_f_xk, x - x_k), x - x_k) + L_3 * (x - x_k).norm()**4 / 4.\n",
    "    \n",
    "    return r_k(y) - r_k(x) - torch.matmul(grad_rk_x, y - x)\n",
    "\n",
    "def g_phi_tau(x, f, x_k, grad2_f_xk, tau, L_3):\n",
    "    \n",
    "    return gradient(f, x_k) + torch.matmul(grad2_f_xk, x - x_k) + 0.5 * 1./tau**2 * (\n",
    "    gradient(f, x_k + tau * (x - x_k)) + gradient(f, x_k - tau * (x - x_k)) - 2. * gradient(f, x_k)\n",
    "    ) + L_3 * (x - x_k).norm()**2 * (x - x_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def BDGM(f, x_k, L_3 = 1., tau = 1e-5, eps = 1e-10, max_iter = 1e2, axil_eps = 1e1, axil_iter = 1e2):\n",
    "    iterations = []\n",
    "    grad2_f_xk = gradient2(f, x_k)\n",
    "    y_k = x_k\n",
    "    delt = eps**1.5 / (gradient(f, x_k).norm()**0.5 + grad2_f_xk.norm()**1.5 / L_3**0.5)\n",
    "    #tau = 3. * delt / (8 * (2 + 2**0.5) * gradient(f, x_k).norm()) \n",
    "    S_k = 2. * ((2 + 2**0.5) / L_3 * gradient(f, x_k).norm())**(1./3)\n",
    "    \n",
    "    while(len(iterations) <= max_iter):\n",
    "        iterations.append(y_k)\n",
    "        \n",
    "        g = g_phi_tau(y_k, f, x_k, grad2_f_xk, tau, L_3)\n",
    "        if(g.norm() <= 1./6 * gradient(f, y_k).norm() - delt):\n",
    "            break\n",
    "              \n",
    "        grad_rk_yk = torch.matmul(grad2_f_xk, y_k - x_k) + L_3 * (y_k - x_k).norm()**2 * (y_k - x_k)\n",
    "        g_brk = lambda y: torch.matmul(g, y - y_k) + 2 * (1 + 1./2**0.5) * b_r_k(y_k, y, f, x_k, L_3, grad_rk_yk, grad2_f_xk)\n",
    "        grad_g_brk = lambda y: g + 2 * (1 + 1./2**0.5) * (\n",
    "            torch.matmul(grad2_f_xk, y - x_k) + L_3 * (y - x_k).norm()**2 * (y - x_k) - grad_rk_yk)\n",
    "        \n",
    "        y_k = NAG(f = g_brk, x_0 = y_k, gradient = grad_g_brk, eps = axil_eps, max_iter = axil_iter).x\n",
    "        \n",
    "        if((y_k - x_k).norm() > S_k):\n",
    "            L_3 *= 2\n",
    "            #continue\n",
    "            \n",
    "    return Iterations(y_k, iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bin_srch(f, x_bound, y_bound, max_iter = 1e1):\n",
    "    iterations = []\n",
    "    x_0, x_1 = x_bound\n",
    "    y_0, y_1 = y_bound\n",
    "    \n",
    "    while(len(iterations) <= max_iter):\n",
    "        \n",
    "        x = (x_0 + x_1) / 2.\n",
    "        f_x = f(x)\n",
    "        \n",
    "        iterations.append(x)\n",
    "        \n",
    "        if(f_x >= y_0):\n",
    "            if(f_x <= y_1):\n",
    "                return Iterations(x, iterations)\n",
    "            else:\n",
    "                x_0 = x\n",
    "        else:\n",
    "            x_1 = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def HyperFast(f, x_0, L_3 = 1., tau = 1e-5, eps = 1e-7, max_iter = 10, axil_eps = 1e1, axil_iter = 1e2):\n",
    "    iterations = []\n",
    "    A_k = 0.\n",
    "    y_k = x_k = x_k_v = torch.zeros(n)\n",
    "    \n",
    "    y_k = BDGM(f, x_k_v, L_3, tau, eps, axil_eps = axil_eps, axil_iter = axil_iter).x\n",
    "    lam_k = (7./12) / (0.75 * L_3 * (y_k - x_k_v).norm()**2)         \n",
    "    a_k = 0.5 * (lam_k + (lam_k**2 + 4 * lam_k * A_k)**0.5)\n",
    "    A_k = A_k + a_k\n",
    "    x_k = x_k - a_k * gradient(f, y_k)\n",
    "    iterations.append(y_k)\n",
    "    \n",
    "    while(len(iterations) <= max_iter):  \n",
    "        \n",
    "        xi_t = lambda t: (1 - t)**2 * A_k * (1.5 * L_3) / (2 * t) * (\n",
    "        BDGM(f, ((1 - t) * x_k + t * y_k), L_3, tau, eps, axil_eps = axil_eps).x - ((1 - t) * x_k + t * y_k)).norm()**2\n",
    "        t = bin_srch(xi_t, [0., 1.], [0.5, 0.75]).x\n",
    "        \n",
    "        lam_k = (1 - t)**2 * A_k / t\n",
    "        a_k = 0.5 * (lam_k + (lam_k**2 + 4 * lam_k * A_k)**0.5)\n",
    "        A_k = A_k + a_k\n",
    "        y_k = BDGM(f, ((1 - t) * x_k + t * y_k), L_3, tau, eps, axil_eps = axil_eps, axil_iter = axil_iter).x\n",
    "        x_k = x_k - a_k * gradient(f, y_k)\n",
    "        \n",
    "        iterations.append(y_k)\n",
    "        \n",
    "    return Iterations(y_k, iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_0 = torch.tensor(random(n))\n",
    "x_k = torch.tensor(random(n))\n",
    "y_k = torch.tensor(random(n))\n",
    "\n",
    "f = log_reg\n",
    "L_3 = 1.\n",
    "tau = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-963eb5d78b63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0miters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHyperFast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mL_3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mx_hf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-1bb5470904f2>\u001b[0m in \u001b[0;36mHyperFast\u001b[1;34m(f, x_0, L_3, tau, eps, max_iter, axil_eps, axil_iter)\u001b[0m\n\u001b[0;32m     15\u001b[0m         xi_t = lambda t: (1 - t)**2 * A_k * (1.5 * L_3) / (2 * t) * (\n\u001b[0;32m     16\u001b[0m         BDGM(f, ((1 - t) * x_k + t * y_k), L_3, tau, eps, axil_eps = axil_eps).x - ((1 - t) * x_k + t * y_k)).norm()**2\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbin_srch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxi_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.75\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mlam_k\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mA_k\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'x'"
     ]
    }
   ],
   "source": [
    "iters = HyperFast(f, x_0, L_3, tau)\n",
    "x_hf = iters.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_nag = NAG(f, x_0, lambda x: gradient(f, x), max_iter = 1e5).x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_nag - x_hf).norm(), abs(f(x_nag - f(x_hf)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
